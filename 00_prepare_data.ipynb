{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape dataset to fit Llama 3.2 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "from data import go_emotions, uk2us, nrc_emotions, emotag\n",
    "#from functions import americanize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert UK to US Spelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to replace British spellings with American spellings\n",
    "def americanize(string):\n",
    "    for british_spelling, american_spelling in uk2us.items():\n",
    "        string = re.sub(f'(?<![a-zA-Z]){british_spelling}(?![a-zA-Z])', american_spelling, string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = go_emotions['train']\n",
    "df_test = go_emotions['test']\n",
    "df_val = go_emotions['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d7f7d82dde14bb898bb48495b2d26d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=5427), Label(value='0 / 5427'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/multiprocessing/popen_fork.py:66: RuntimeWarning: Using fork() can cause Polars to deadlock in the child process.\n",
      "In addition, using fork() with Python in general is a recipe for mysterious\n",
      "deadlocks and crashes.\n",
      "\n",
      "The most likely reason you are seeing this error is because you are using the\n",
      "multiprocessing module on Linux, which uses fork() by default. This will be\n",
      "fixed in Python 3.14. Until then, you want to use the \"spawn\" context instead.\n",
      "\n",
      "See https://docs.pola.rs/user-guide/misc/multiprocessing/ for details.\n",
      "\n",
      "  self.pid = os.fork()\n"
     ]
    }
   ],
   "source": [
    "df_train['us_text'] = df_train['text'].parallel_apply(americanize)\n",
    "df_test['us_text'] = df_test['text'].parallel_apply(americanize)\n",
    "df_val['us_text'] = df_val['text'].parallel_apply(americanize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_parquet(\"output/goemotions_train_us.parquet\", index=False)\n",
    "df_test.to_parquet(\"output/goemotions_test_us.parquet\", index=False)\n",
    "df_val.to_parquet(\"output/goemotions_val_us.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(\"output/goemotions_train_us.parquet\")\n",
    "df_test = pd.read_parquet(\"output/goemotions_test_us.parquet\")\n",
    "df_val = pd.read_parquet(\"output/goemotions_val_us.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create N-Grams for Dictionary-Based Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary mapping words to their associated emotions\n",
    "nrc_emotions_grouped = nrc_emotions[nrc_emotions['association']!=0].groupby('word')['emotion'].apply(list).reset_index()\n",
    "d_nrc_emotions = {i['word']:i['emotion'] for i in nrc_emotions_grouped.to_dict(orient='records')}\n",
    "# Save to json\n",
    "with open(\"data/nrc_lexicon/nrc_emotions.json\", \"w\") as f:\n",
    "    json.dump(d_nrc_emotions, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ngrams(text, n=2, dic=d_nrc_emotions):\n",
    "    l_ngrams = []\n",
    "    l_emotions = []\n",
    "    for w, e in dic.items():\n",
    "        if w in text:\n",
    "            # Tokenize the text into words\n",
    "            words = text.split()\n",
    "            \n",
    "            ngrams = []\n",
    "            emotions = []\n",
    "            \n",
    "            # Loop through the words to find the specified word\n",
    "            for i in range(len(words)):\n",
    "                if words[i].lower() == w:\n",
    "                    # Collect n-grams centered around the specified word\n",
    "                    start = max(0, i - (n // 2))\n",
    "                    end = min(len(words), i + (n // 2) + 1)\n",
    "                    ngram = \" \".join(words[start:end])\n",
    "\n",
    "                    # Check for negation\n",
    "                    doc = nlp(ngram)\n",
    "                    if all(token.dep_ != \"neg\" for token in doc):\n",
    "                        ngrams.append(ngram)\n",
    "                        emotions.append(e)\n",
    "            \n",
    "            l_ngrams.append(ngrams)\n",
    "            l_emotions.append(emotions)\n",
    "    \n",
    "    return (\n",
    "        [x for x in l_ngrams if x], \n",
    "        [x for x in l_emotions if x]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['this sad in']], [[['sadness']]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_ngrams(\"I've never been this sad in my life\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5253778894574b998a0a603a2c8819e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=5427), Label(value='0 / 5427'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25f91cee19e4062829dd2cbe23496dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=679), Label(value='0 / 679'))), HB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58c47e180d5b4f1baf3dfb98a7a67130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=679), Label(value='0 / 679'))), HB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train[['ngrams', 'emotions']] = pd.DataFrame(\n",
    "    df_train['us_text'].parallel_apply(create_ngrams).tolist(), index=df_train.index\n",
    ")\n",
    "df_test[['ngrams', 'emotions']] = pd.DataFrame(\n",
    "    df_test['us_text'].parallel_apply(create_ngrams).tolist(), index=df_test.index\n",
    ")\n",
    "df_val[['ngrams', 'emotions']] = pd.DataFrame(\n",
    "    df_val['us_text'].parallel_apply(create_ngrams).tolist(), index=df_val.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/go_emotions/emotions.txt', \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Remove any trailing newline characters\n",
    "lines = [line.strip() for line in lines]\n",
    "\n",
    "d_go_emotions = {i:e for i,e in enumerate(lines)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emo(labels):\n",
    "    return [d_go_emotions[label] for label in labels]\n",
    "\n",
    "df_train['l_emotions'] = df_train['labels'].apply(lambda x: [d_go_emotions[label] for label in x])\n",
    "df_train['emotions'] = df_train['l_emotions'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>us_text</th>\n",
       "      <th>ngrams</th>\n",
       "      <th>emotions</th>\n",
       "      <th>l_emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My favourite food is anything I didn't have to...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>My favorite food is anything I didn't have to ...</td>\n",
       "      <td>[[My favorite food], [favorite food is]]</td>\n",
       "      <td>['neutral']</td>\n",
       "      <td>[neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now if he does off himself, everyone will thin...</td>\n",
       "      <td>[27]</td>\n",
       "      <td>Now if he does off himself, everyone will thin...</td>\n",
       "      <td>[[a laugh screwing]]</td>\n",
       "      <td>['neutral']</td>\n",
       "      <td>[neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
       "      <td>[2]</td>\n",
       "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
       "      <td>[]</td>\n",
       "      <td>['anger']</td>\n",
       "      <td>[anger]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To make her feel threatened</td>\n",
       "      <td>[14]</td>\n",
       "      <td>To make her feel threatened</td>\n",
       "      <td>[]</td>\n",
       "      <td>['fear']</td>\n",
       "      <td>[fear]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dirty Southern Wankers</td>\n",
       "      <td>[3]</td>\n",
       "      <td>Dirty Southern Wankers</td>\n",
       "      <td>[]</td>\n",
       "      <td>['annoyance']</td>\n",
       "      <td>[annoyance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43405</th>\n",
       "      <td>Added you mate well I’ve just got the bow and ...</td>\n",
       "      <td>[18]</td>\n",
       "      <td>Added you mate well I’ve just got the bow and ...</td>\n",
       "      <td>[[so happily join], [the hunting aspect, you h...</td>\n",
       "      <td>['love']</td>\n",
       "      <td>[love]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43406</th>\n",
       "      <td>Always thought that was funny but is it a refe...</td>\n",
       "      <td>[6]</td>\n",
       "      <td>Always thought that was funny but is it a refe...</td>\n",
       "      <td>[[Always thought that]]</td>\n",
       "      <td>['confusion']</td>\n",
       "      <td>[confusion]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43407</th>\n",
       "      <td>What are you talking about? Anything bad that ...</td>\n",
       "      <td>[3]</td>\n",
       "      <td>What are you talking about? Anything bad that ...</td>\n",
       "      <td>[[Anything bad that], [[NAME] fault -], [only ...</td>\n",
       "      <td>['annoyance']</td>\n",
       "      <td>[annoyance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43408</th>\n",
       "      <td>More like a baptism, with sexy results!</td>\n",
       "      <td>[13]</td>\n",
       "      <td>More like a baptism, with sexy results!</td>\n",
       "      <td>[]</td>\n",
       "      <td>['excitement']</td>\n",
       "      <td>[excitement]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43409</th>\n",
       "      <td>Enjoy the ride!</td>\n",
       "      <td>[17]</td>\n",
       "      <td>Enjoy the ride!</td>\n",
       "      <td>[]</td>\n",
       "      <td>['joy']</td>\n",
       "      <td>[joy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43410 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text labels  \\\n",
       "0      My favourite food is anything I didn't have to...   [27]   \n",
       "1      Now if he does off himself, everyone will thin...   [27]   \n",
       "2                         WHY THE FUCK IS BAYLESS ISOING    [2]   \n",
       "3                            To make her feel threatened   [14]   \n",
       "4                                 Dirty Southern Wankers    [3]   \n",
       "...                                                  ...    ...   \n",
       "43405  Added you mate well I’ve just got the bow and ...   [18]   \n",
       "43406  Always thought that was funny but is it a refe...    [6]   \n",
       "43407  What are you talking about? Anything bad that ...    [3]   \n",
       "43408            More like a baptism, with sexy results!   [13]   \n",
       "43409                                    Enjoy the ride!   [17]   \n",
       "\n",
       "                                                 us_text  \\\n",
       "0      My favorite food is anything I didn't have to ...   \n",
       "1      Now if he does off himself, everyone will thin...   \n",
       "2                         WHY THE FUCK IS BAYLESS ISOING   \n",
       "3                            To make her feel threatened   \n",
       "4                                 Dirty Southern Wankers   \n",
       "...                                                  ...   \n",
       "43405  Added you mate well I’ve just got the bow and ...   \n",
       "43406  Always thought that was funny but is it a refe...   \n",
       "43407  What are you talking about? Anything bad that ...   \n",
       "43408            More like a baptism, with sexy results!   \n",
       "43409                                    Enjoy the ride!   \n",
       "\n",
       "                                                  ngrams        emotions  \\\n",
       "0               [[My favorite food], [favorite food is]]     ['neutral']   \n",
       "1                                   [[a laugh screwing]]     ['neutral']   \n",
       "2                                                     []       ['anger']   \n",
       "3                                                     []        ['fear']   \n",
       "4                                                     []   ['annoyance']   \n",
       "...                                                  ...             ...   \n",
       "43405  [[so happily join], [the hunting aspect, you h...        ['love']   \n",
       "43406                            [[Always thought that]]   ['confusion']   \n",
       "43407  [[Anything bad that], [[NAME] fault -], [only ...   ['annoyance']   \n",
       "43408                                                 []  ['excitement']   \n",
       "43409                                                 []         ['joy']   \n",
       "\n",
       "         l_emotions  \n",
       "0         [neutral]  \n",
       "1         [neutral]  \n",
       "2           [anger]  \n",
       "3            [fear]  \n",
       "4       [annoyance]  \n",
       "...             ...  \n",
       "43405        [love]  \n",
       "43406   [confusion]  \n",
       "43407   [annoyance]  \n",
       "43408  [excitement]  \n",
       "43409         [joy]  \n",
       "\n",
       "[43410 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
